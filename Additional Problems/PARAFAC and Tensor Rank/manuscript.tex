\documentclass[a4paper,10pt]{article}

\usepackage{cite}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amstext,amsmath,amssymb}
\usepackage[shortlabels]{enumitem}

\setlength{\oddsidemargin}{0cm} %
\setlength{\evensidemargin}{0cm} %
\setlength{\topmargin}{0cm} %
\setlength{\textwidth}{16cm} %
\setlength{\textheight}{22.5cm} %

\pagestyle{fancy}
\newcommand{\assunto}{PARAFAC and Tensor Rank}

\sloppy

\begin{document}

\input{front.tex}
\thispagestyle{empty}

\newpage

\thispagestyle{empty}

\begin{enumerate}
\renewcommand{\labelenumi}{{\Large\bfseries\arabic{enumi}.}}
   
    \item We know that if we have the tensor defined as
    
        \begin{align}
            \mathcal{X} = \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{2},
        \end{align}

        then if we have $\boldsymbol{b}_{1} = \boldsymbol{b}_{2}$ and $\boldsymbol{c}_{1} = \boldsymbol{c}_{2}$ we can guarantee that $\mathcal{X}$ is rank one. We can begin this proof by using the associativity property of the outer product to write tensor $\mathcal{X}$ as

        \begin{align}
            \mathcal{X} &= \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{2}, \\
            \mathcal{X} &= \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1}, \\
            \mathcal{X} &= (\boldsymbol{a}_{1} + \boldsymbol{a}_{2}) \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1},
        \end{align}
        
        and by inspecting above expression we can observe that independent of the vectors $\boldsymbol{a}_{1}$ and $\boldsymbol{a}_{2}$ being collinear we will have a rank one tensor defined as
        
        \begin{align}
            \mathcal{X} &= \boldsymbol{a}_{3} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1},
        \end{align}
        
        where $\boldsymbol{a}_{3} = \boldsymbol{a}_{1} + \boldsymbol{a}_{2}$. In a similar fashion, if we have $\boldsymbol{b}_{1} \neq \boldsymbol{b}_{2}$ and $\boldsymbol{c}_{1} = \boldsymbol{c}_{2}$ then we can rewrite the tensor as

        \begin{align}
            \mathcal{X} &= \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{2}, \\
            \mathcal{X} &= \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{1}, \\
            \mathcal{X} &= (\boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2}) \circ \boldsymbol{c}_{1},
        \end{align}

        but since we can guarantee that the vectors $\boldsymbol{b}_{1}$ and $\boldsymbol{b}_{2}$ are not collinear then we know that the sum in above expression cannot be further reduced. Thus, we will have a tensor 
        composed of the sum of two subtensors of rank one meaning that our tensor $\mathcal{X}$  will be a rank two tensor.

    \item To show that the tensor rank is a property we will begin by writting the following multilinear transformations
    
        \begin{align}
            \mathcal{X} &= \mathcal{S} \times_{1} \boldsymbol{A}^{(1)} \cdots \times_{3} \boldsymbol{A}^{(3)} \in \mathbb{C}^{I_{1} \times \cdots \times I_{N}}, \\
            \mathcal{S} &= \mathcal{X} \times_{1} \boldsymbol{A}^{(1)^{\text{H}}} \cdots \times_{3} \boldsymbol{A}^{(3)^{\text{H}}} \in \mathbb{C}^{I_{1} \times \cdots \times I_{N}}.
        \end{align}

        First we can begin by defining the core tensor $\mathcal{S}$ by its PARAFAC Decomposition as

        \begin{align}
            \mathcal{S} = \sum^{R}_{r = 1} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{s}^{(N)}_{r},
        \end{align}

        and by returning to the original transformation we can rewrite it as 

        \begin{align}
            \mathcal{X} &= \left(\sum^{R}_{r = 1} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{s}^{(N)}_{r}\right) \times_{1} \boldsymbol{A}^{(1)} \cdots \times_{3} \boldsymbol{A}^{(3)}, \\
            \mathcal{X} &= \left(\sum^{R}_{r = 1} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{s}^{(N)}_{r} \times_{1} \boldsymbol{A}^{(1)} \cdots \times_{3} \boldsymbol{A}^{(3)}\right), \\
            \mathcal{X} &= \sum^{R}_{r = 1} \boldsymbol{A}^{(1)} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{A}^{(N)} \boldsymbol{s}^{(N)}_{r}.
        \end{align}

        Now considering the inverse multilinear transformation and that $\boldsymbol{A}^{(n)^{\text{H}}} \boldsymbol{A}^{(n)} = \boldsymbol{I}, \forall n \in \{1, \cdots, N\}$ we can rewrite tensor $\mathcal{S}$ as

        \begin{align}
            \mathcal{S} &= \mathcal{X} \times_{1} \boldsymbol{A}^{(1)^{\text{H}}} \cdots \times_{3} \boldsymbol{A}^{(3)^{\text{H}}}, \\
            \mathcal{S} &= \left(\sum^{R}_{r = 1} \boldsymbol{A}^{(1)} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{A}^{(N)} \boldsymbol{s}^{(N)}_{r} \right) \times_{1} \boldsymbol{A}^{(1)^{\text{H}}} \cdots \times_{3} \boldsymbol{A}^{(3)^{\text{H}}}, \\
            \mathcal{S} &= \left(\sum^{R}_{r = 1} \boldsymbol{A}^{(1)} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{A}^{(N)} \boldsymbol{s}^{(N)}_{r} \times_{1} \boldsymbol{A}^{(1)^{\text{H}}} \cdots \times_{3} \boldsymbol{A}^{(3)^{\text{H}}} \right), \\
            \mathcal{S} &= \sum^{R}_{r = 1} \boldsymbol{A}^{(1)^{\text{H}}} \boldsymbol{A}^{(1)} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{A}^{(N)^{\text{H}}} \boldsymbol{A}^{(N)} \boldsymbol{s}^{(N)}_{r}, \\
            \mathcal{S} &= \sum^{R}_{r = 1} \boldsymbol{s}^{(1)}_{r} \circ \cdots \circ \boldsymbol{s}^{(3)}_{r}
        \end{align}

        and since the tensor rank is defined by the minimum number of rank one tensors that together compose the original tensor then by analysing above expressions we can observe that we have bounded tensors 
        $\mathcal{X}$ and $\mathcal{S}$ to the same number of elements that compose them. Thus, the tensor rank is indeed a property and

        \begin{align}
            \text{rank}\left(\mathcal{X}\right) = \text{rank}\left(\mathcal{S}\right).
        \end{align}

        Moreover, if we consider the case of dimension reduction where $\mathcal{S} \in \mathbb{C}^{R_{1} \times \cdots \times R_{N}}$ with $R_{n} << I_{n}, \forall n \in \{1, \cdots, N\}$ the if we can guarantee that
        $\boldsymbol{A}^{(n)^{\dagger}} \boldsymbol{A}^{(n)} = \boldsymbol{I}, \forall n \in \{1, \cdots, N\}$ then we should once more have the same tensor rank for the case where the factor matrices are defined as $\boldsymbol{A}^{n} \in \mathbb{C}^{I_{n} \times R_{n}}, \forall \{1, \cdots, N\}$.
        
    \item Proof that the following tensor has rank three if all the vector pairs are non collinear
    
        \begin{align}
            \mathcal{X} = \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{1} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{2} \in \mathbb{C}^{I_{1} \times I_{2} \times I_{3}},
        \end{align}

        First we need to show that above tensor have a multilinear transformation defined as 
            
        \begin{align}
            \mathcal{X} &= \mathcal{S} \times_{1} \boldsymbol{A} \times_{2} \boldsymbol{B} \times_{3} \boldsymbol{C} \in \mathbb{C}^{I_{1} \times I_{2} \times I_{N}},  
        \end{align}

        where the unfoldings of the core tensor $\mathcal{S}$

        \begin{align}
            \left[\boldsymbol{S}\right]_{(1)} = 
            \begin{bmatrix}
                1 & 0 & 0 & 1 \\
                0 & 1 & 0 & 0
            \end{bmatrix},  
            \left[\boldsymbol{S}\right]_{(2)} = 
            \begin{bmatrix}
                1 & 0 & 0 & 0 \\
                0 & 1 & 1 & 0
            \end{bmatrix},  
            \left[\boldsymbol{S}\right]_{(3)} = 
            \begin{bmatrix}
                1 & 0 & 0 & 1 \\
                0 & 0 & 1 & 0
            \end{bmatrix},  
        \end{align}

        thus we have that the tensor $\mathcal{X}$ can be written 

        \begin{align}
            \left[\boldsymbol{X}\right]_{(1)} &= \boldsymbol{A} \left[\boldsymbol{S}\right]_{(1)} (\boldsymbol{C} \otimes \boldsymbol{B})^{\text{T}}, \\
            \left[\boldsymbol{X}\right]_{(1)} &= 
            \begin{bmatrix}
                \boldsymbol{a}_{1} & \boldsymbol{a}_{2}
            \end{bmatrix}
            \begin{bmatrix}
                1 & 0 & 0 & 1 \\
                0 & 1 & 0 & 0
            \end{bmatrix} 
            \begin{bmatrix}
                (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{1})^{\text{T}} & (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{2})^{\text{T}} & (\boldsymbol{c}_{2} \otimes \boldsymbol{b}_{1})^{\text{T}} & (\boldsymbol{c}_{2} \otimes \boldsymbol{b}_{2})^{\text{T}}
            \end{bmatrix}, \\
            \left[\boldsymbol{X}\right]_{(1)} &= 
            \begin{bmatrix}
                \boldsymbol{a}_{1} & \boldsymbol{a}_{2}
            \end{bmatrix}
            \begin{bmatrix}
                (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{1})^{\text{T}} + (\boldsymbol{c}_{2} \otimes \boldsymbol{b}_{2})^{\text{T}} \\
                (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{2})^{\text{T}}
            \end{bmatrix}, \\
            \left[\boldsymbol{X}\right]_{(1)} &= \boldsymbol{a}_{1} (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{1})^{\text{T}} + \boldsymbol{a}_{1} (\boldsymbol{c}_{2} \otimes \boldsymbol{b}_{2})^{\text{T}} + \boldsymbol{a}_{2} (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{2})^{\text{T}},
        \end{align}

        and by doing the folding we get

        \begin{align}
            \mathcal{X} &= \boldsymbol{a}_{1} (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{1})^{\text{T}} + \boldsymbol{a}_{1} (\boldsymbol{c}_{2} \otimes \boldsymbol{b}_{2})^{\text{T}} + \boldsymbol{a}_{2} (\boldsymbol{c}_{1} \otimes \boldsymbol{b}_{2})^{\text{T}}, \\
            \mathcal{X} &= \boldsymbol{a}_{1} \circ \boldsymbol{b}_{1} \circ \boldsymbol{c}_{1} + \boldsymbol{a}_{1} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{2} + \boldsymbol{a}_{2} \circ \boldsymbol{b}_{2} \circ \boldsymbol{c}_{1}.
        \end{align}

        We also know from the previous problem that the tensor rank is indeed a property. Thus, the tensor $\mathcal{X}$ and the core tensor $\mathcal{S}$ of its multilinear transformation will have the same tensor rank.
        Now, we only need to proof that either one of them are a tensor with rank three. The easiest way to do this is by working with the core tensor of the multilinear transformation, the tensor $\mathcal{S}$, and start 
        a proof by contradiction defining that $rank(\mathcal{S}) = 2$. This means that we can write the PARAFAC Decomposition of this tensor assunto

        \begin{align}
            \mathcal{S} = \sum^{2}_{r = 1} \boldsymbol{s}^{(1)}_{r} \circ \boldsymbol{s}^{(2)}_{r} \circ \boldsymbol{s}^{(3)}_{r},
        \end{align}
        
    
    \item 

        \begin{enumerate}
            
            \item

            \item

            \item 

        \end{enumerate}

\end{enumerate}

%\bibliographystyle{ieeetr}
%\bibliography{bibliography.bib}

\end{document}

